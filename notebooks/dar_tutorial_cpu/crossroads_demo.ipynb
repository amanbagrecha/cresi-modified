{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import skimage\n",
    "import osmnx as ox\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.spatial\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_filename = 'demo_config.json'\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/cresi\n"
     ]
    }
   ],
   "source": [
    "cresi_dir = '/opt/cresi'\n",
    "%cd {cresi_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = os.path.join(cresi_dir, 'cresi')\n",
    "config_dir = os.path.join(cresi_dir, src_dir, 'configs')\n",
    "\n",
    "data_dir  = os.path.join(cresi_dir, 'data')\n",
    "raw_data_dir = os.path.join(cresi_dir, data_dir, 'raw_data')\n",
    "clipped_data_dir = os.path.join(cresi_dir, data_dir, 'clipped_data')\n",
    "eight_bit_dir = os.path.join(cresi_dir, data_dir, '8bit_data')\n",
    "sliced_dir = os.path.join(cresi_dir, data_dir, 'sliced_data')\n",
    "\n",
    "results_dir = os.path.join(cresi_dir, 'results')\n",
    "mask_pred_dir = os.path.join(results_dir, 'folds')\n",
    "mask_stitched_dir = os.path.join(results_dir, 'stitched/mask_norm')\n",
    "\n",
    "# make dirs\n",
    "#for d in [weight_dir, test_im_raw_dir, test_im_clip_dir, test_final_dir, mask_stitched_dir, mask_pred_dir]:\n",
    "#    os.makedirs(d, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = os.path.join(config_dir, config_filename)\n",
    "\n",
    "# update directories\n",
    "with open(config_path, 'r+') as f:\n",
    "    data = json.load(f)\n",
    "    data['path_src'] = src_dir\n",
    "    data['path_data_root'] = data_dir\n",
    "    data['results_dir'] = results_dir\n",
    "    \n",
    "    data['clipped_data_dir'] = clipped_data_dir\n",
    "    data['eight_bit_dir'] = eight_bit_dir\n",
    "    data['sliced_dir'] = sliced_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write new values\n",
    "os.remove(config_path)\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert 16bit MS to 8bit, 3 band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor im_name in os.listdir(test_im_clip_dir):\\n    break\\n    ds = rasterio.open(os.path.join(test_im_clip_dir, im_name))\\n\\n    n_ds = rasterio.open(\\n        os.path.join(test_final_dir, im_name),\\n        'w',\\n        driver='GTiff',\\n        height=ds.shape[0],\\n        width=ds.shape[1],\\n        count=3, # 3 bands\\n        dtype='uint8', # 8 bit\\n        crs=ds.crs, # copy from orig\\n        transform=ds.transform # lonlat bounds, copy from orig\\n    )\\n    \\n    # 3 band orig\\n    if len(ds.dtypes) == 3:\\n        n_ds.write_band(1, ds.read(1).astype('uint8'))\\n        n_ds.write_band(2, ds.read(2).astype('uint8'))\\n        n_ds.write_band(3, ds.read(3).astype('uint8'))\\n    elif len(ds.dtypes) == 8:\\n        n_ds.write_band(1, ds.read(5).astype('uint8'))\\n        n_ds.write_band(2, ds.read(3).astype('uint8'))\\n        n_ds.write_band(3, ds.read(2).astype('uint8'))\\n    else:\\n        print ('Unknown source type.')\\n    \\n    n_ds.close()\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import rasterio \n",
    "\"\"\"\n",
    "for im_name in os.listdir(test_im_clip_dir):\n",
    "    break\n",
    "    ds = rasterio.open(os.path.join(test_im_clip_dir, im_name))\n",
    "\n",
    "    n_ds = rasterio.open(\n",
    "        os.path.join(test_final_dir, im_name),\n",
    "        'w',\n",
    "        driver='GTiff',\n",
    "        height=ds.shape[0],\n",
    "        width=ds.shape[1],\n",
    "        count=3, # 3 bands\n",
    "        dtype='uint8', # 8 bit\n",
    "        crs=ds.crs, # copy from orig\n",
    "        transform=ds.transform # lonlat bounds, copy from orig\n",
    "    )\n",
    "    \n",
    "    # 3 band orig\n",
    "    if len(ds.dtypes) == 3:\n",
    "        n_ds.write_band(1, ds.read(1).astype('uint8'))\n",
    "        n_ds.write_band(2, ds.read(2).astype('uint8'))\n",
    "        n_ds.write_band(3, ds.read(3).astype('uint8'))\n",
    "    elif len(ds.dtypes) == 8:\n",
    "        n_ds.write_band(1, ds.read(5).astype('uint8'))\n",
    "        n_ds.write_band(2, ds.read(3).astype('uint8'))\n",
    "        n_ds.write_band(3, ds.read(2).astype('uint8'))\n",
    "    else:\n",
    "        print ('Unknown source type.')\n",
    "    \n",
    "    n_ds.close()\n",
    "\"\"\"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im_name: 000-001-RGB.tif\n",
      "temp file: /opt/cresi/data/clipped_data/000-001-RGB_clip.vrt\n",
      "output_file: /opt/cresi/data/clipped_data/000-001-RGB_clip_60cm.tif\n"
     ]
    }
   ],
   "source": [
    "im_name = [z for z in os.listdir(raw_data_dir) if z.endswith('.tif')][0]\n",
    "print(\"im_name:\", im_name)\n",
    "\n",
    "test_im_raw = os.path.join(raw_data_dir, im_name)\n",
    "test_im_tmp = os.path.join(clipped_data_dir, im_name.split('.tif')[0] + '_clip.vrt')\n",
    "print(\"temp file:\", test_im_tmp)\n",
    "\n",
    "test_im_clip = os.path.join(clipped_data_dir, im_name.split('.tif')[0] + '_clip_60cm.tif')\n",
    "print(\"output_file:\", test_im_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim to latlong bounds\n",
    "#ulx, uly, lrx, lry = 39.25252, -6.7580, 39.28430, -6.7880  # v0\n",
    "#!gdal_translate -projwin {ulx} {uly} {lrx} {lry} {test_im_raw} {test_im_tmp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample 30 cm imagery to 60 cm\n",
    "#!gdal_translate -outsize 50% 50% {test_im_tmp} {test_im_clip}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im_files: ['000-001-RGB.tif']\n",
      "Input file size is 5057, 5057\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "# this works much better, but we can't use gdal \n",
    "from cresi import create_8bit_images\n",
    "\n",
    "# Convert 16-bit multispectral test data to 8-bit RGB\n",
    "create_8bit_images.dir_to_8bit(raw_data_dir, eight_bit_dir,\n",
    "                              command_file_loc='',\n",
    "                              rescale_type=\"perc\",\n",
    "                              percentiles=[2,98],\n",
    "                              band_order=[]) # specify [5,3,2] if MS channels. Here we are using RGB itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display our image\n",
    "#im_name = [z for z in os.listdir(eight_bit_dir) if z.endswith('.tif')][0]\n",
    "#im_path = os.path.join(eight_bit_dir, im_name)\n",
    "#im = skimage.io.imread(im_path)\n",
    "\n",
    "#skimage.io.imshow(im) \n",
    "#skimage.io.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice image into processable chunks\n",
    "slice_x, slice_y defined in config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing tile_im.py..\n",
      "slice command: python /opt/cresi/cresi/data_prep/tile_im.py /opt/cresi/cresi/configs/demo_config.json\n",
      "Output path for sliced images: /opt/cresi/data/sliced_data\n",
      "processing starting\n",
      "Slicing /opt/cresi/data/8bit_data\n",
      "im_path /opt/cresi/data/8bit_data/000-001-RGB.tif\n",
      "im.shape: (5057, 5057, 3)\n",
      "n pixels: 25573249\n",
      "  len df; 16\n",
      "  Time to slice arrays: 4.893352270126343 seconds\n",
      "  Total pixels in test image(s): 25573249\n",
      "df saved to file: /opt/cresi/results/tile_df.csv\n"
     ]
    }
   ],
   "source": [
    "%run -i cresi/01_slice.py { config_path }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_dir: /opt/cresi/results/folds\n",
      "paths: {'masks': '', 'images': '/opt/cresi/data/sliced_data'}\n",
      "fn_mapping: {'masks': <function <lambda> at 0x7fb109dd3af0>}\n",
      "image_suffix: \n",
      "num_workers: 0\n",
      "fold: 0\n",
      "run eval.Evaluator.predict()...\n",
      "prefix: \n",
      "Creating datasets within pytorch_utils/eval.py()...\n",
      "val_indexes:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "len val_dl: 144\n",
      "self.num_workers 4\n",
      "Running eval.read_model()...\n",
      "load model with cpu\n",
      "  model sucessfully loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                               | 0/144 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▊                                                                                                                      | 1/144 [00:02<06:03,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█▋                                                                                                                     | 2/144 [00:04<05:36,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|██▍                                                                                                                    | 3/144 [00:06<05:15,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|███▎                                                                                                                   | 4/144 [00:09<05:10,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|████▏                                                                                                                  | 5/144 [00:11<05:04,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|████▉                                                                                                                  | 6/144 [00:13<05:14,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|█████▊                                                                                                                 | 7/144 [00:15<05:12,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██████▌                                                                                                                | 8/144 [00:18<05:07,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|███████▍                                                                                                               | 9/144 [00:20<05:03,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|████████▏                                                                                                             | 10/144 [00:22<04:58,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|█████████                                                                                                             | 11/144 [00:24<04:55,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|█████████▊                                                                                                            | 12/144 [00:26<04:48,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|██████████▋                                                                                                           | 13/144 [00:29<04:49,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████████▍                                                                                                          | 14/144 [00:31<04:41,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████████▎                                                                                                         | 15/144 [00:33<04:41,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█████████████                                                                                                         | 16/144 [00:35<04:39,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████████▉                                                                                                        | 17/144 [00:37<04:39,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|██████████████▊                                                                                                       | 18/144 [00:40<04:40,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|███████████████▌                                                                                                      | 19/144 [00:42<04:42,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|████████████████▍                                                                                                     | 20/144 [00:44<04:37,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█████████████████▏                                                                                                    | 21/144 [00:46<04:34,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|██████████████████                                                                                                    | 22/144 [00:49<04:31,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|██████████████████▊                                                                                                   | 23/144 [00:51<04:28,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|███████████████████▋                                                                                                  | 24/144 [00:53<04:28,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|████████████████████▍                                                                                                 | 25/144 [00:55<04:22,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█████████████████████▎                                                                                                | 26/144 [00:57<04:20,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|██████████████████████▏                                                                                               | 27/144 [01:00<04:19,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|██████████████████████▉                                                                                               | 28/144 [01:02<04:15,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████████████▊                                                                                              | 29/144 [01:04<04:13,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|████████████████████████▌                                                                                             | 30/144 [01:06<04:08,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████████████████████▍                                                                                            | 31/144 [01:08<04:05,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██████████████████████████▏                                                                                           | 32/144 [01:10<04:03,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|███████████████████████████                                                                                           | 33/144 [01:13<04:02,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████████████▊                                                                                          | 34/144 [01:15<03:58,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|████████████████████████████▋                                                                                         | 35/144 [01:17<04:02,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|█████████████████████████████▌                                                                                        | 36/144 [01:19<04:01,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██████████████████████████████▎                                                                                       | 37/144 [01:22<04:00,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|███████████████████████████████▏                                                                                      | 38/144 [01:24<03:59,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|███████████████████████████████▉                                                                                      | 39/144 [01:26<03:55,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|████████████████████████████████▊                                                                                     | 40/144 [01:28<03:48,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|█████████████████████████████████▌                                                                                    | 41/144 [01:30<03:45,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██████████████████████████████████▍                                                                                   | 42/144 [01:33<03:45,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███████████████████████████████████▏                                                                                  | 43/144 [01:35<03:42,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|████████████████████████████████████                                                                                  | 44/144 [01:37<03:40,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|████████████████████████████████████▉                                                                                 | 45/144 [01:39<03:35,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████████████████████████████▋                                                                                | 46/144 [01:42<03:38,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████████████████▌                                                                               | 47/144 [01:44<03:38,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███████████████████████████████████████▎                                                                              | 48/144 [01:46<03:35,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|████████████████████████████████████████▏                                                                             | 49/144 [01:48<03:33,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████████████████▉                                                                             | 50/144 [01:51<03:28,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|█████████████████████████████████████████▊                                                                            | 51/144 [01:53<03:25,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|██████████████████████████████████████████▌                                                                           | 52/144 [01:55<03:22,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███████████████████████████████████████████▍                                                                          | 53/144 [01:57<03:20,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|████████████████████████████████████████████▎                                                                         | 54/144 [01:59<03:19,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|█████████████████████████████████████████████                                                                         | 55/144 [02:01<03:14,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|█████████████████████████████████████████████▉                                                                        | 56/144 [02:04<03:12,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|██████████████████████████████████████████████▋                                                                       | 57/144 [02:06<03:09,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███████████████████████████████████████████████▌                                                                      | 58/144 [02:08<03:08,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████████████████████████████████████████████████▎                                                                     | 59/144 [02:10<03:07,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|█████████████████████████████████████████████████▏                                                                    | 60/144 [02:12<03:03,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|█████████████████████████████████████████████████▉                                                                    | 61/144 [02:15<03:00,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████████████████████████▊                                                                   | 62/144 [02:17<02:58,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|███████████████████████████████████████████████████▋                                                                  | 63/144 [02:19<02:58,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████████████████████████████████████████████████████▍                                                                 | 64/144 [02:21<02:58,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|█████████████████████████████████████████████████████▎                                                                | 65/144 [02:24<02:57,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|██████████████████████████████████████████████████████                                                                | 66/144 [02:26<02:55,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|██████████████████████████████████████████████████████▉                                                               | 67/144 [02:28<02:52,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|███████████████████████████████████████████████████████▋                                                              | 68/144 [02:30<02:49,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████████████████████████████████████████████████████████▌                                                             | 69/144 [02:32<02:47,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|█████████████████████████████████████████████████████████▎                                                            | 70/144 [02:35<02:45,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|██████████████████████████████████████████████████████████▏                                                           | 71/144 [02:37<02:52,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████████████████████████████                                                           | 72/144 [02:40<02:48,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|███████████████████████████████████████████████████████████▊                                                          | 73/144 [02:42<02:43,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|████████████████████████████████████████████████████████████▋                                                         | 74/144 [02:44<02:40,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████████████████████████████████████████████▍                                                        | 75/144 [02:46<02:35,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|██████████████████████████████████████████████████████████████▎                                                       | 76/144 [02:49<02:33,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|███████████████████████████████████████████████████████████████                                                       | 77/144 [02:51<02:30,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|███████████████████████████████████████████████████████████████▉                                                      | 78/144 [02:53<02:27,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|████████████████████████████████████████████████████████████████▋                                                     | 79/144 [02:55<02:26,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████████████████████████████████████████████████████████████████▌                                                    | 80/144 [02:57<02:22,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|██████████████████████████████████████████████████████████████████▍                                                   | 81/144 [03:00<02:21,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|███████████████████████████████████████████████████████████████████▏                                                  | 82/144 [03:02<02:19,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|████████████████████████████████████████████████████████████████████                                                  | 83/144 [03:05<02:21,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|████████████████████████████████████████████████████████████████████▊                                                 | 84/144 [03:07<02:20,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████████████████████████████████████████████████████████████████████▋                                                | 85/144 [03:09<02:18,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████████████████████████▍                                               | 86/144 [03:12<02:14,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|███████████████████████████████████████████████████████████████████████▎                                              | 87/144 [03:14<02:11,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|████████████████████████████████████████████████████████████████████████                                              | 88/144 [03:16<02:07,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|████████████████████████████████████████████████████████████████████████▉                                             | 89/144 [03:18<02:04,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████████████████████████████████████████████████████████████▊                                            | 90/144 [03:21<02:03,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████████████████████████████████████████████████████████████████████████▌                                           | 91/144 [03:23<02:00,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|███████████████████████████████████████████████████████████████████████████▍                                          | 92/144 [03:25<01:57,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|████████████████████████████████████████████████████████████████████████████▏                                         | 93/144 [03:27<01:54,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|█████████████████████████████████████████████████████████████████████████████                                         | 94/144 [03:29<01:51,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|█████████████████████████████████████████████████████████████████████████████▊                                        | 95/144 [03:32<01:49,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████████████████████████████████████████████████████████▋                                       | 96/144 [03:34<01:47,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|███████████████████████████████████████████████████████████████████████████████▍                                      | 97/144 [03:36<01:45,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|████████████████████████████████████████████████████████████████████████████████▎                                     | 98/144 [03:38<01:41,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|█████████████████████████████████████████████████████████████████████████████████▏                                    | 99/144 [03:41<01:39,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|█████████████████████████████████████████████████████████████████████████████████▎                                   | 100/144 [03:43<01:36,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████████████████████████████████████████████████████████                                   | 101/144 [03:45<01:34,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|██████████████████████████████████████████████████████████████████████████████████▉                                  | 102/144 [03:47<01:32,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████████████████████████████████████████████████████████████████████████████████▋                                 | 103/144 [03:49<01:30,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|████████████████████████████████████████████████████████████████████████████████████▌                                | 104/144 [03:52<01:28,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|█████████████████████████████████████████████████████████████████████████████████████▎                               | 105/144 [03:54<01:25,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|██████████████████████████████████████████████████████████████████████████████████████▏                              | 106/144 [03:56<01:24,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|██████████████████████████████████████████████████████████████████████████████████████▉                              | 107/144 [03:58<01:22,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████████████████████████████████████████████████████████████████████████████████████▊                             | 108/144 [04:01<01:20,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|████████████████████████████████████████████████████████████████████████████████████████▌                            | 109/144 [04:03<01:17,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|█████████████████████████████████████████████████████████████████████████████████████████▍                           | 110/144 [04:05<01:15,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|██████████████████████████████████████████████████████████████████████████████████████████▏                          | 111/144 [04:07<01:13,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████████████████████████████████████████████████████████████████████████████████████████                          | 112/144 [04:09<01:11,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████████████████████████████████████████████████████████████████████████████████████████▊                         | 113/144 [04:12<01:09,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|████████████████████████████████████████████████████████████████████████████████████████████▋                        | 114/144 [04:14<01:06,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████████▍                       | 115/144 [04:16<01:04,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|██████████████████████████████████████████████████████████████████████████████████████████████▎                      | 116/144 [04:18<01:01,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|███████████████████████████████████████████████████████████████████████████████████████████████                      | 117/144 [04:20<00:59,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|███████████████████████████████████████████████████████████████████████████████████████████████▉                     | 118/144 [04:23<00:57,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████████████████████████████████████████████████████████████████████████████████████████████▋                    | 119/144 [04:25<00:55,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|█████████████████████████████████████████████████████████████████████████████████████████████████▌                   | 120/144 [04:27<00:52,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                  | 121/144 [04:29<00:50,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|███████████████████████████████████████████████████████████████████████████████████████████████████▏                 | 122/144 [04:31<00:48,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|███████████████████████████████████████████████████████████████████████████████████████████████████▉                 | 123/144 [04:34<00:46,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                | 124/144 [04:36<00:44,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████▌               | 125/144 [04:38<00:42,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████▍              | 126/144 [04:40<00:40,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏             | 127/144 [04:43<00:38,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████████████████████████████████████████████████████████████████████████████████████████████████████             | 128/144 [04:45<00:35,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊            | 129/144 [04:47<00:33,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋           | 130/144 [04:49<00:31,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▍          | 131/144 [04:52<00:28,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▎         | 132/144 [04:54<00:26,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████         | 133/144 [04:56<00:24,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 134/144 [04:58<00:22,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▋       | 135/144 [05:00<00:19,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌      | 136/144 [05:03<00:17,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▎     | 137/144 [05:05<00:15,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏    | 138/144 [05:07<00:13,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉    | 139/144 [05:09<00:10,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊   | 140/144 [05:11<00:08,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌  | 141/144 [05:14<00:06,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍ | 142/144 [05:16<00:04,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏| 143/144 [05:18<00:02,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "  eval.py - predict() - executing...\n",
      "  eval.py - predict() - batch.shape: torch.Size([1, 3, 512, 512])\n",
      "  eval.py - predict() - pred1.shape: torch.Size([1, 8, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 144/144 [05:20<00:00,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete_eval.py.process_batch()  predicted.shape; (1, 512, 512, 8)\n",
      "Time to run 1 folds for 16 = 322.2066354751587 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%run -i cresi/02_eval.py { config_path }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate results\n",
    "\n",
    "The 02_eval.py script produce a multi-channel road masks for each image tile.  Each channel of this mask corresponds to a unique speed range.  For each of the testing tiles, the predicted mask will look something like the plot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_pred.shape: (8, 468, 468)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask_pred_file = [z for z in os.listdir(mask_pred_dir) if z.endswith('.tif')][0]\n",
    "mask_pred_path = os.path.join(mask_pred_dir, mask_pred_file)\n",
    "mask_pred = skimage.io.imread(mask_pred_path)\n",
    "print(\"mask_pred.shape:\", mask_pred.shape)\n",
    "\n",
    "# plot all layers\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 9))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    if i < (len(axes.flatten()) - 1):\n",
    "        title = 'Mask Channel {}'.format(str(i))\n",
    "    else:\n",
    "        title = 'Aggregate' \n",
    "    ax.imshow(mask_pred[i,:,:])\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stitch slices back together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running stitch.py...\n",
      "num_folds 1\n",
      "prefix:  \n",
      "post_process_image - w, h: 5057 5057\n",
      "0 / 16\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1300,1300,8) (468,468,8) (1300,1300,8) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/cresi/cresi/03_stitch.py:283\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;66;03m##############################################################################\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 283\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/cresi/cresi/03_stitch.py:208\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;66;03m# execute\u001b[39;00m\n\u001b[1;32m    207\u001b[0m t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 208\u001b[0m name, mask_norm, mask_raw, overlay_count \u001b[38;5;241m=\u001b[39m \u001b[43mpost_process_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mim_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mim_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mim_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuper_verbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m t2 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    216\u001b[0m ttot \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m t2 \u001b[38;5;241m-\u001b[39m t1\n",
      "File \u001b[0;32m/opt/cresi/cresi/03_stitch.py:92\u001b[0m, in \u001b[0;36mpost_process_image\u001b[0;34m(df_pos_, data_dir, num_classes, im_prefix, super_verbose)\u001b[0m\n\u001b[1;32m     89\u001b[0m     mask_raw[y0:y1, x0:x1] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m mask_slice_refine\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# add mask to mask_raw\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     mask_raw[y0:y1, x0:x1, :] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m mask_slice_refine\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# per channel\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# for c in range(num_classes):\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m#    mask_raw[y0:y1, x0:x1, c] += mask_slice_refine[:,:,c]\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# update count\u001b[39;00m\n\u001b[1;32m     97\u001b[0m overlay_count[y0:y1, x0:x1] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((slice_y, slice_x), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1300,1300,8) (468,468,8) (1300,1300,8) "
     ]
    }
   ],
   "source": [
    "%run -i cresi/03_stitch.py { config_path }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Inspect the output\u001b[39;00m\n\u001b[1;32m      2\u001b[0m plot_all_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m mask_pred_file \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mz\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_stitched_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendswith\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.tif\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m mask_pred_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(mask_stitched_dir, mask_pred_file)\n\u001b[1;32m      5\u001b[0m mask_pred \u001b[38;5;241m=\u001b[39m skimage\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mimread(mask_pred_path)\u001b[38;5;66;03m# + '.2.tif')\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Inspect the output\n",
    "plot_all_layers = False\n",
    "mask_pred_file = [z for z in os.listdir(mask_stitched_dir) if z.endswith('.tif')][0]\n",
    "mask_pred_path = os.path.join(mask_stitched_dir, mask_pred_file)\n",
    "mask_pred = skimage.io.imread(mask_pred_path)# + '.2.tif')\n",
    "print(\"mask_pred.shape:\", mask_pred.shape)\n",
    "\n",
    "# plot final layer\n",
    "fig_width, fig_height = 12, 12\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "_ = ax.imshow(mask_pred[-1,:,:])\n",
    "_ = ax.set_title('Aggregate - ' + mask_pred_file)\n",
    "\n",
    "# plot all layers (optional)\n",
    "if plot_all_layers:\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(20, 11))\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        if i < (len(axes.flatten()) - 1):\n",
    "            title = 'Mask Channel {}'.format(str(i))\n",
    "        else:\n",
    "            title = 'Aggregate' \n",
    "        ax.imshow(mask_pred[i,:,:])\n",
    "        ax.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "The 04_skeletonize script creates a graph from the aggregate mask via a multi-step process:\n",
    "    \n",
    "1. Refine aggregate mask via smoothing, openings, and closings.\n",
    "\n",
    "2. Extract a skeleton of the refined mask.\n",
    "\n",
    "3. Build a graph from the skeleton.  \n",
    "\n",
    "4. Clean out spurious edges and complete missing connections.\n",
    "\n",
    "5. Output a csv of graph edges.  This csv output is included as a convenient intermediate step, since if speeds and geographic coordinates are not required we can forego Sections 5.4 and 5.5.\n",
    "\n",
    "The 04_skeletonize.py script is multi-threaded to improve speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run -i cresi/04_skeletonize.py { config_path }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the output\n",
    "csv_path = os.path.join(results_dir, 'wkt_submission_nospeed.csv')\n",
    "df = pd.read_csv(csv_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### 5.4. 05_wkt_to_G.py\n",
    "\n",
    "This script reads the csv output by 04_skeletonize.py back into graph format (which is very quick), and then uses the metadata encoded in our geotiff test image to assign geographic coordinates to the graph.  Assigning geo-coordinates for thousands of nodes is a computationally intensive process, so this script is multi-threaded to improve performance. The script outputs a [NetworkX](https://networkx.github.io) graph structure in ~60 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run -i cresi/05_wkt_to_G.py { config_path }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# inspect the output\n",
    "gpickle_file = [z for z in os.listdir(os.path.join(results_dir, 'graphs')) if z.endswith('.gpickle')][0]\n",
    "gpickle_path = os.path.join(results_dir, 'graphs', gpickle_file)\n",
    "G0 = nx.read_gpickle(gpickle_path)\n",
    "_, _ = ox.plot_graph(G0, figsize=(12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
